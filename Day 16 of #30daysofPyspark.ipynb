{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acac3a1c-8a7b-4b52-b596-1085642e47d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31244740-15ae-4a29-82c9-d371b6e39fd3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<h3>Explode in pyspark<\\h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04405e1f-295c-4ece-9e5f-64c47d858a8a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------------------+\n|rer| id|              fruits|\n+---+---+--------------------+\n|  2|  1|[apple, banana, c...|\n|  3|  2|     [grape, orange]|\n+---+---+--------------------+\n\n+---+---+-----------------------+\n|rer|id |fruits                 |\n+---+---+-----------------------+\n|2  |1  |[apple, banana, cherry]|\n|3  |2  |[grape, orange]        |\n+---+---+-----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"explode_example\").getOrCreate()\n",
    "# Create a DataFrame with an array column\n",
    "data = [(2,1, [\"apple\", \"banana\", \"cherry\"]), (3,2, [\"grape\", \"orange\"])]\n",
    "\n",
    "col=[\"rer\",\"id\", \"fruits\"]\n",
    "\n",
    "df = spark.createDataFrame(data,col )\n",
    "df.show()\n",
    "df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81bd0fd1-7323-4991-8e1c-6a89840d4704",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+\n|rer| id| fruit|\n+---+---+------+\n|  2|  1| apple|\n|  2|  1|banana|\n|  2|  1|cherry|\n|  3|  2| grape|\n|  3|  2|orange|\n+---+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select(\"rer\",\"id\", explode(\"fruits\").alias(\"fruit\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43ffe765-6a98-4cfc-8737-eba2fb1f3ad4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<h3>question 2<\\h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daefbb11-3692-4b2e-b350-237d3e646ab7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-------------------------------------------------------------------------------------------+\n|Country|id |States                                                                                     |\n+-------+---+-------------------------------------------------------------------------------------------+\n|India  |1  |[Kerala, Andhra Pradesh, Karnataka, Tamil Nadu, Telangana, Assam, Bihar, Punjab, Karnataka]|\n|canada |2  |[Ontario, Alberta]                                                                         |\n+-------+---+-------------------------------------------------------------------------------------------+\n\n+-------+---+--------------+\n|Country|id |States        |\n+-------+---+--------------+\n|India  |1  |Kerala        |\n|India  |1  |Andhra Pradesh|\n|India  |1  |Karnataka     |\n|India  |1  |Tamil Nadu    |\n|India  |1  |Telangana     |\n|India  |1  |Assam         |\n|India  |1  |Bihar         |\n|India  |1  |Punjab        |\n|India  |1  |Karnataka     |\n|canada |2  |Ontario       |\n|canada |2  |Alberta       |\n+-------+---+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"explode_example\").getOrCreate()\n",
    "Data=[(\"India\",\"1\",[\"Kerala\",\"Andhra Pradesh\",\"Karnataka\",\"Tamil Nadu\",\"Telangana\",\"Assam\" ,\"Bihar\",\"Punjab\",\"Karnataka\"]),(\"canada\",\"2\",[\"Ontario\",\"Alberta\"])]\n",
    "Shema=[\"Country\",\"id\", \"States\"]\n",
    "\n",
    "df = spark.createDataFrame(Data, [\"Country\",\"id\", \"States\"])\n",
    "df.show(truncate=False)\n",
    "# Use explode to transform the array column into separate rows\n",
    "exploded_df = df.select(\"Country\",\"id\", explode(\"States\").alias(\"States\"))\n",
    "\n",
    "exploded_df.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Day 16 of #30daysofPyspark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
