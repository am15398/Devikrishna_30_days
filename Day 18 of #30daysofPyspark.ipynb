{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acac3a1c-8a7b-4b52-b596-1085642e47d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04405e1f-295c-4ece-9e5f-64c47d858a8a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n|          timestamp|user_id|\n+-------------------+-------+\n|2023-09-11 12:00:00|      1|\n|2023-09-11 13:30:00|      2|\n|2023-09-11 14:45:00|      1|\n|2023-09-11 16:15:00|      3|\n+-------------------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"MostFrequentUser\").getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "# Sample log data\n",
    "log_data = [\n",
    "    (\"2023-09-11 12:00:00\", \"1\"),\n",
    "    (\"2023-09-11 13:30:00\", \"2\"),\n",
    "    (\"2023-09-11 14:45:00\", \"1\"),\n",
    "    (\"2023-09-11 16:15:00\", \"3\")\n",
    "]\n",
    "\n",
    "# Create a DataFrame from the sample log data and schema\n",
    "logtable = spark.createDataFrame(log_data, [\"timestamp\",\"user_id\"])\n",
    "\n",
    "# Show the contents of the log table\n",
    "logtable.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81bd0fd1-7323-4991-8e1c-6a89840d4704",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n|user_id|login_count|\n+-------+-----------+\n|      1|          2|\n|      2|          1|\n|      3|          1|\n+-------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Group the DataFrame by user_id and count the number of logins for each user\n",
    "user_counts = logtable.groupBy(\"user_id\").agg(count(\"*\").alias(\"login_count\"))\n",
    "user_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89781c54-23c3-4218-8495-060d0d5e0ad5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n|user_id|login_count|\n+-------+-----------+\n|      1|          2|\n+-------+-----------+\n\n+-------+\n|user_id|\n+-------+\n|      1|\n+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# Find the user with the highest login count\n",
    "most_frequent_user=user_counts.orderBy(desc(\"login_count\")).limit(1)\n",
    "most_frequent_user.show()\n",
    "most_frequent_user.select(\"user_id\").show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Day 18 of #30daysofPyspark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
